name: Run Tests

on:
  push:
    branches:
      - master

jobs:
  # Job (1): Run testing in parallel against multiples OSs and Python versions
  test:
    name: Test
    runs-on: ${{ matrix.os }}
    # Determines whether the entire workflow should pass/fail based on parallel jobs
    continue-on-error: ${{ matrix.ok-fail }}
    defaults:
      # This ensures each step gets properly configured bash shell for conda commands to work
      run:
        shell: bash -l {0}
    strategy:
      fail-fast: true
      matrix:
        # OSs to test
        os: [ubuntu-latest, macos-latest, windows-latest]
        # Python versions to test
        python-version: [3.8, 3.9]
        # By default everything should pass for the workflow to pass
        ok-fail: [false]
        include:
          # Latest mac and windows fail to install deps properly so tell workflow its ok if these fail
          - os: macos-latest
            python-version: 3.9
            ok-fail: true
          - os: windows-latest
            python-version: 3.9
            ok-fail: true
    steps:
      # 1. Step up miniconda
      - name: Download and setup Miniconda
        uses: conda-incubator/setup-miniconda@v2
        with:
          miniconda-version: "latest"
          python-version: ${{ matrix.python-version }}

      # 2. Check out latest code on github
      - name: Checkout Code
        uses: actions/checkout@v2

      # 3. Install common sci-py packages via conda as well as testing packages and requirements
      - name: Install Dependencies
        run: |
          conda activate test
          conda env list
          conda install -y pip numpy pandas scipy matplotlib seaborn scikit-learn
          conda install -y -c conda-forge pytest coveralls
          pip install . -r requirements.txt

      # 4. Actually run the tests with coverage
      - name: Run Tests
        run: |
          conda activate test
          conda env list
          coverage run --source=utilz -m pytest

      # 5. Send coverage to coveralls.io but waiting on parallelization to finish
      # Not using the official github action in the marketplace to upload because it requires a .lcov file, which pytest doesn't generate. It's just easier to use the coveralls python library which does the same thing, but works with pytest.
      - name: Upload Coverage
        # The coveralls python package has some 422 server issues with uploads from github-actions so try both service providers, for more see:
        # https://github.com/TheKevJames/coveralls-python/issues/252
        run: coveralls --service=github || coveralls --service=github-actions
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          COVERALLS_FLAG_NAME: $${{ matrix}}
          COVERALLS_PARALLEL: true

  # Job (2): Send a finish notification to coveralls.io to integrate coverage across parallel tests
  coveralls:
    name: Indicate completion to coveralls.io
    needs: test
    runs-on: ubuntu-latest
    container: python:3-slim
    steps:
      - name: Finished
        run: |
          pip3 install --upgrade coveralls
          coveralls --service=github --finish || coveralls --service=github-actions --finish
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  # Job (3): Build package and upload to conda/pypi
  deploy:
    name: Build and deploy package
    needs: coveralls
    runs-on: ubuntu-latest
    steps:
      - name: Say Hi
        shell: bash
        run: |
          echo "hello world. I havent been configured for deployment yet!"
